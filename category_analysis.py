# -*- coding: utf-8 -*-
"""Category_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XuUcSOe7n4FiMn6En1LFxKs_bLv5RkpZ
"""

# Step 2: Install necessary dependencies (if not already installed)
!pip install openpyxl

# Step 3: Import required libraries
import pandas as pd

# Step 1: Mount Google Drive to access files
from google.colab import drive
drive.mount('/content/drive')
# Step 2: List files in your Google Drive to find your Excel file
# !ls /content/drive/MyDrive/

!ls /content/drive/MyDrive/LLM_Chatbot/NPJ_In-Basket/Each_Category_Analysis.xlsx

# Example: Reading an Excel file from a specific folder in Google Drive
file_path = '/content/drive/MyDrive/LLM_Chatbot/NPJ_In-Basket/Each_Category_Analysis.xlsx'  # Replace with your actual path

each_category_df = pd.read_excel(file_path, engine='openpyxl')

# Display the DataFrame
# category.head()

clustered_llm_df = '/content/drive/MyDrive/LLM_Chatbot/NPJ_In-Basket/clustered_LLM_outputs.xlsx'  # Replace with your actual path
clustered_llm_df = pd.read_excel(clustered_llm_df, engine='openpyxl')

round4_df = '/content/drive/MyDrive/LLM_Chatbot/NPJ_In-Basket/Round4_InBasket_Grading_MDs.xlsx'  # Replace with your actual path
round4_df = pd.read_excel(round4_df, engine='openpyxl')

# Check the columns in the DataFrame
print(clustered_llm_df.columns)
print(each_category_df.columns)

# Step 5: Merge the two DataFrames based on the "prompt" column
# We'll merge the two DataFrames on the 'prompt' column to match the rows
# and bring in the 'Category' information from 'Each_Category_Analysis.xlsx'
# Use how='outer' to include all keys from both DataFrames
merged_df = pd.merge(clustered_llm_df, each_category_df[['prompt', 'Category Number']], on='prompt', how='outer', suffixes=('', '_new'))

# Step 6: Update the "Category" column in clustered_LLM_outputs with the new Category values
# Check if 'Category Number_new' exists before accessing it
if 'Category Number_new' in merged_df.columns:
    merged_df['Category Number'] = merged_df['Category Number_new'].combine_first(merged_df['Category Number'])

# Step 7: Drop the temporary 'Category_new' column that was created during the merge
# Check if 'Category Number_new' exists before dropping it
if 'Category Number_new' in merged_df.columns:
    merged_df.drop(columns=['Category Number_new'], inplace=True)

# Step 8: Save the updated DataFrame back to an Excel file
merged_df.to_excel('Updated_clustered_LLM_outputs.xlsx', index=False, engine='openpyxl')

# Step 9: Download the updated file back to your local machine
files.download('Updated_clustered_LLM_outputs.xlsx')

"""Each Category's Performance"""

# Step 1: Filter the DataFrame where Type is "human" and "GPT"
human_df = clustered_llm_df[clustered_llm_df['Type'] == 'human']
gpt_df = clustered_llm_df[clustered_llm_df['Type'] == 'GPT']

# Step 2: Calculate the mean of "HBTotal" for each "Category Number" where "Type" is "human"
human_means = human_df.groupby('Category Number')['HBTotal'].mean().reset_index()
print("Mean HBTotal for Human by Category Number:")
print(human_means)

# Step 3: Calculate the mean of "HBTotal" for each "Category Number" where "Type" is "GPT"
gpt_means = gpt_df.groupby('Category Number')['HBTotal'].mean().reset_index()
print("\nMean HBTotal for GPT by Category Number:")
print(gpt_means)

import numpy as np
import matplotlib.pyplot as plt
from math import pi

# Step 1: Define the data for Human and GPT
categories = ['Test Results', 'Side Effects', 'Medication Question', 'Radiation Treatment',
              'Medical Oncology', 'Surgical Oncology', 'Care Coordination',
              'Lab/Radiology/Pathology', 'Care Journey']
num_categories = len(categories)

# Mean HBTotal values for Human and GPT by category
human_values = [16.083333, 18.048780, 18.100000, 18.354167, 19.166667,
                19.250000, 16.800000, 19.071429, 16.000000]
gpt_values = [19.208333, 17.797619, 18.039474, 16.720000, 17.333333,
              18.625000, 19.100000, 19.095238, 18.944444]

# Step 2: Create the radar chart
# The angles of the chart
angles = [n / float(num_categories) * 2 * pi for n in range(num_categories)]
angles += angles[:1]  # Complete the circle

# Add the Human and GPT data to close the loop
human_values += human_values[:1]
gpt_values += gpt_values[:1]

# Step 3: Initialize the radar chart
fig, ax = plt.subplots(figsize=(6, 6), subplot_kw=dict(polar=True))

# Step 4: Plot the data for Human
ax.plot(angles, human_values, linewidth=2, linestyle='solid', label='Human Care Team', color='#f5a525')
ax.fill(angles, human_values, '#f5a525', alpha=0.3)

# Step 5: Plot the data for GPT
ax.plot(angles, gpt_values, linewidth=2, linestyle='solid', label='RadOnc-GPT', color='#2196F3')
ax.fill(angles, gpt_values, '#2196F3', alpha=0.3)

# Step 6: Add labels for each category
ax.set_xticks(angles[:-1])
ax.set_xticklabels(categories, fontsize=10)

# Step 7: Add title and legend
# plt.title('Mean HBTotal for Human and GPT by Category', size=16, color='black', y=1.1)
plt.legend(loc='upper right', bbox_to_anchor=(1.31, 1.1))

# Step 8: Set y-label limits for the radial axis
ax.set_rlabel_position(30)
ax.set_yticks([15, 17, 19])
ax.set_yticklabels(["15", "17", "19"], color="grey", size=8)
ax.set_ylim(15, 20)
plt.rcParams['figure.dpi'] = 280


# Step 9: Show the radar chart
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns

# Step 1: Define the category mapping for the Category Number
category_mapping = {
    1: 'Test Results',
    2: 'Side Effects',
    3: 'Medication Question',
    4: 'Radiation Treatment Question',
    5: 'Medical Oncology Question',
    6: 'Surgical Oncology Question',
    7: 'Care Coordination/Logistics',
    8: 'Lab/Radiology/Pathology Reports',
    9: 'Care Journey Questions'
}

# Step 2: Filter the DataFrame where Type is "human" and "GPT"
human_df = clustered_llm_df[clustered_llm_df['Type'] == 'human']
gpt_df = clustered_llm_df[clustered_llm_df['Type'] == 'GPT']

# Step 3: Calculate the mean of "HBTotal" for each "Category Number" where "Type" is "human"
human_means = human_df.groupby('Category Number')['HBTotal'].mean().reset_index()

# Step 4: Calculate the mean of "HBTotal" for each "Category Number" where "Type" is "GPT"
gpt_means = gpt_df.groupby('Category Number')['HBTotal'].mean().reset_index()

# Step 5: Map the Category Number to their respective names
human_means['Category Number'] = human_means['Category Number'].map(category_mapping)
gpt_means['Category Number'] = gpt_means['Category Number'].map(category_mapping)

# Step 6: Add a column for "Type" to differentiate human and GPT
human_means['Type'] = 'Human'
gpt_means['Type'] = 'GPT'

# Step 7: Combine both datasets into one for easy visualization
combined_means = pd.concat([human_means, gpt_means])

# Step 8: Visualize the result using seaborn
plt.figure(figsize=(12, 6))
ax = sns.barplot(x='Category Number', y='HBTotal', hue='Type', data=combined_means, palette=['#f5a525', '#2196F3'])

# Add labels and title
# plt.title('Mean HBTotal for Human and GPT by Category', fontsize=16)
plt.xlabel('Category', fontsize=14)
plt.ylabel('Mean Grader Total', fontsize=14)

# Rotate x-axis labels for better readability
plt.xticks(rotation=45, ha='right')

# Step 9: Add data labels on the bars
for p in ax.patches:
    height = p.get_height()
    ax.annotate(f'{height:.2f}',
                (p.get_x() + p.get_width() / 2., height),  # Position the label
                ha='center', va='bottom',  # Horizontal alignment center, vertical bottom
                fontsize=10, color='black', xytext=(0, 5), textcoords='offset points')

# Display the plot
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Step 1: Define category mapping for labels
category_mapping = {
    1: 'Test Results',
    2: 'Side Effects',
    3: 'Medication Question',
    4: 'Radiation Treatment Question',
    5: 'Medical Oncology Question',
    6: 'Surgical Oncology Question',
    7: 'Care Coordination/Logistics',
    8: 'Lab/Radiology/Pathology Reports',
    9: 'Care Journey Questions'
}

# Step 2: Replace "Category Number" with the actual category names for visualization
clustered_llm_df['Category Name'] = clustered_llm_df['Category Number'].map(category_mapping)

# Step 3: Calculate the mean of "HBTotal" for Human and GPT by Category
human_df = clustered_llm_df[clustered_llm_df['Type'] == 'human']
gpt_df = clustered_llm_df[clustered_llm_df['Type'] == 'GPT']

human_means = human_df.groupby('Category Name')['HBTotal'].mean().reset_index()
gpt_means = gpt_df.groupby('Category Name')['HBTotal'].mean().reset_index()

# Step 4: Combine Human and GPT mean values into a single DataFrame for easy access
combined_means = pd.merge(human_means, gpt_means, on='Category Name', suffixes=('_Human', '_GPT'))

# Step 5: Count the occurrences of each category for the pie chart
category_counts = clustered_llm_df['Category Name'].value_counts()

# Step 6: Plot the pie chart and add the bar chart information as annotations
fig, ax = plt.subplots(figsize=(10, 8))

explode = (0.05,) * len(category_counts)  # Slightly separate all slices
wedges, texts, autotexts = ax.pie(
    category_counts,
    labels=category_counts.index,
    autopct='%1.1f%%',
    startangle=140,
    colors=plt.cm.Paired.colors,
    explode=explode,
    pctdistance=0.85,
    wedgeprops=dict(width=0.3)  # Create a donut-style pie chart
)

# Step 7: Add both the Human and GPT means as annotations near each slice
for i, p in enumerate(wedges):
    category = category_counts.index[i]  # Get the category name
    human_mean = combined_means[combined_means['Category Name'] == category]['HBTotal_Human'].values[0]
    gpt_mean = combined_means[combined_means['Category Name'] == category]['HBTotal_GPT'].values[0]

    # Compute the angle of the pie slice's center to position the text
    angle = (p.theta2 - p.theta1) / 2. + p.theta1
    x = np.cos(np.radians(angle))
    y = np.sin(np.radians(angle))

    # Adjust the annotation position slightly further away from the pie
    horizontal_alignment = {-1: "right", 1: "left"}[int(np.sign(x))]
    connection_line = ax.annotate(
        f'Human: {human_mean:.2f}\nGPT: {gpt_mean:.2f}',
        xy=(x, y), xytext=(1.35 * np.sign(x), 1.4 * y),
        textcoords="data", ha=horizontal_alignment, fontsize=10,
        bbox=dict(boxstyle="round,pad=0.3", edgecolor="black", facecolor="white"),
        arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=0.2", color='black')
    )

# Customize text size for percentage labels and category names
for text in texts:
    text.set_fontsize(14)
for autotext in autotexts:
    autotext.set_fontsize(12)

# Title for the combined chart
plt.title('Category Distribution with Mean HBTotal for Human and GPT', fontsize=16)

# Ensure the pie chart is circular
plt.axis('equal')
plt.rcParams['figure.dpi'] = 180

# Display the chart
plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Step 1: Define category mapping for labels
category_mapping = {
    1: 'Test Results',
    2: 'Side Effects',
    3: 'Medication Question',
    4: 'Radiation Treatment Question',
    5: 'Medical Oncology Question',
    6: 'Surgical Oncology Question',
    7: 'Care Coordination/Logistics',
    8: 'Lab/Radiology/Pathology Reports',
    9: 'Care Journey Questions'
}

# Step 2: Replace "Category Number" with the actual category names for visualization
clustered_llm_df['Category Name'] = clustered_llm_df['Category Number'].map(category_mapping)

# Step 3: Calculate the mean of "HBTotal" for Human and GPT by Category
human_df = clustered_llm_df[clustered_llm_df['Type'] == 'human']
gpt_df = clustered_llm_df[clustered_llm_df['Type'] == 'GPT']

human_means = human_df.groupby('Category Name')['HBTotal'].mean().reset_index()
gpt_means = gpt_df.groupby('Category Name')['HBTotal'].mean().reset_index()

# Step 4: Combine Human and GPT mean values into a single DataFrame for easy access
combined_means = pd.merge(human_means, gpt_means, on='Category Name', suffixes=('_Human', '_GPT'))

# Step 5: Count the occurrences of each category for the pie chart
category_counts = clustered_llm_df['Category Name'].value_counts()

# Step 6: Plot the pie chart and add the bar chart information as annotations
fig, ax = plt.subplots(figsize=(10, 8))

explode = (0.05,) * len(category_counts)  # Slightly separate all slices
wedges, texts, autotexts = ax.pie(
    category_counts,
    labels=category_counts.index,
    autopct='%1.1f%%',
    startangle=140,
    colors=plt.cm.Paired.colors,
    explode=explode,
    pctdistance=0.85,
    wedgeprops=dict(width=0.3)  # Create a donut-style pie chart
)

# Step 7: Add both the Human and GPT means as annotations near each slice
for i, p in enumerate(wedges):
    category = category_counts.index[i]  # Get the category name
    human_mean = combined_means[combined_means['Category Name'] == category]['HBTotal_Human'].values[0]
    gpt_mean = combined_means[combined_means['Category Name'] == category]['HBTotal_GPT'].values[0]

    # Compute the angle of the pie slice's center to position the text
    angle = (p.theta2 - p.theta1) / 2. + p.theta1
    x = np.cos(np.radians(angle))
    y = np.sin(np.radians(angle))

    # Adjust the annotation position slightly further away from the pie
    horizontal_alignment = {-1: "right", 1: "left"}[int(np.sign(x))]

    # Conditional coloring: Yellow if GPT > Human, Blue if GPT < Human
    if gpt_mean > human_mean:
        facecolor = '#f5a525'  # Yellow color
    else:
        facecolor = '#2196F3'  # Blue color

    # Plot the human and GPT values as bar-like annotations near each slice
    ax.annotate(
        f'Human: {human_mean:.2f}\nGPT: {gpt_mean:.2f}',
        xy=(x, y),
        xytext=(1.35 * np.sign(x), 1.4 * y),
        textcoords="data",
        ha=horizontal_alignment, fontsize=10,
        bbox=dict(boxstyle="round,pad=0.3", edgecolor="black", facecolor=facecolor),
        arrowprops=dict(arrowstyle="->", connectionstyle="arc3,rad=0.2", color='black')
    )

# Customize text size for percentage labels and category names
for text in texts:
    text.set_fontsize(14)
for autotext in autotexts:
    autotext.set_fontsize(12)

# Title for the combined chart

# Ensure the pie chart is circular
plt.axis('equal')
plt.rcParams['figure.dpi'] = 180

# Display the chart
plt.tight_layout()
plt.show()

"""Wordcloud from Graders' Comments"""

# Step 1: Install necessary libraries
!pip install wordcloud matplotlib

# Step 2: Import the required libraries
from wordcloud import WordCloud
import matplotlib.pyplot as plt
!pip install wordcloud matplotlib openpyxl pandas nltk

# Step 2: Import the required libraries
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import pandas as pd
import nltk
from nltk import pos_tag
from nltk.tokenize import word_tokenize
nltk.download('punkt')
nltk.download('averaged_perceptron_tagger')

# Step 5: Extract the "Comments" column from round4_df
comments = round4_df['Comments'].dropna().tolist()  # Convert the 'Comments' column to a list, dropping any NaN values
comments_text = " ".join(comments)  # Join all comments into a single string for word cloud generation

# Step 6: Tokenize the text and perform POS tagging
tokens = word_tokenize(comments_text)  # Tokenize the text
tagged_words = pos_tag(tokens)  # Perform POS tagging

# Step 7: Filter only nouns (NN, NNS, NNP, NNPS) and adjectives (JJ, JJR, JJS)
filtered_words = [word for word, pos in tagged_words if pos in ['NN', 'NNS', 'NNP', 'NNPS', 'JJ', 'JJR', 'JJS']]

# Step 8: Join the filtered words back into a single string
filtered_text = " ".join(filtered_words)

# Step 9: Generate the word cloud from the filtered text
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(filtered_text)

# Step 10: Display the word cloud
plt.figure(figsize=(10, 5))
plt.rcParams['figure.dpi'] = 180
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')  # Turn off the axis
plt.show()